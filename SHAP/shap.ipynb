{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f8028de4c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#debugging용 설정\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 및 토크나이저 로딩 중...\n",
      "CUDA 메모리 정리 완료. 사용 가능한 GPU: 1개\n",
      "현재 GPU 메모리 사용량: 0.00 MB\n",
      "27B 모델 로드 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15edad3f2624e8f8f8356fc3900828b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료 (device: cuda:0)\n",
      "임베딩 모델 로딩 중...\n",
      "임베딩 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 1. 모델 및 토크나이저 로드\n",
    "print(\"모델 및 토크나이저 로딩 중...\")\n",
    "model_name = \"google/gemma-3-27b-it\"  # Gemma 3 27B 모델 (instruction tuned)\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# CUDA 메모리 정리\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"CUDA 메모리 정리 완료. 사용 가능한 GPU: {torch.cuda.device_count()}개\")\n",
    "    print(f\"현재 GPU 메모리 사용량: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    token=token\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # 패딩 토큰 설정\n",
    "\n",
    "# 모델 로드 시도\n",
    "try:\n",
    "    print(f\"27B 모델 로드 중...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",  # 자동으로 적절한 장치에 할당\n",
    "        torch_dtype=torch.float32,\n",
    "        token=token\n",
    "    )\n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"모델 로드 완료 (device: {device})\")\n",
    "except Exception as e:\n",
    "    print(f\"GPU 로드 실패: {e}\")\n",
    "    print(\"CPU로 대체 모델 로드 중...\")\n",
    "    \n",
    "    # 메모리 정리\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # CPU로 다시 시도\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"cpu\",\n",
    "        torch_dtype=torch.float32,\n",
    "        token=token\n",
    "    )\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"CPU 모드로 모델 로드 완료 (device: {device})\")\n",
    "\n",
    "# sentence embedding 모델 로드 (다국어 지원 모델)\n",
    "print(\"임베딩 모델 로딩 중...\")\n",
    "embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "print(\"임베딩 모델 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 프롬프트 기반 text generation 함수\n",
    "def summarize_text(text):\n",
    "    \"\"\"텍스트를 요약하는 함수\"\"\"\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Gemma 모델용 instruction 형식 프롬프트\n",
    "    prompt = f\"<start_of_turn>user\\n경제금융 뉴스 기사를 요약해주세요. 중요한 단어 및 내용인 무엇인지 고려해서 요약해주세요.\\n\\n기사: {text}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    \n",
    "    # 토크나이징 및 입력 준비\n",
    "    max_input_length = 2048-128\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    print(\"[DEBUG] input_ids shape:\", inputs[\"input_ids\"].shape)\n",
    "    print(\"[DEBUG] input_ids (앞 30개):\", inputs[\"input_ids\"][0][:30]) \n",
    "    \n",
    "    # 생성 설정\n",
    "    gen_config = {\n",
    "        \"max_new_tokens\": 64,\n",
    "        \"do_sample\": False,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"num_return_sequences\": 1\n",
    "    }\n",
    "    \n",
    "    # 요약 생성\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            print(\">>> input shape:\", inputs[\"input_ids\"].shape)\n",
    "\n",
    "            output = model.generate(**inputs, **gen_config)  # GPU에서 생성\n",
    "            if output.dim() > 1:\n",
    "                output = output[0]  # 첫 번째 결과만 사용 (batch_size=1)\n",
    "\n",
    "            if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "                print(\"[!] generate() 결과에 nan 또는 inf 포함됨 — 디코딩 중단\")\n",
    "                return \"\"\n",
    "\n",
    "            output = output.to(\"cpu\")  # CPU로 옮겨서 안전하게 디코딩\n",
    "            full_response = tokenizer.decode(output, skip_special_tokens=False)  # ✅ 여기 수정!\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[!] generate() 오류: {e}\")\n",
    "            return \"\"\n",
    "        \n",
    "    # 응답 파싱 (모델 응답 부분만 추출)\n",
    "    try:\n",
    "        # Gemma 응답 형식에서 모델 응답 부분만 추출\n",
    "        if \"<start_of_turn>model\" in full_response:\n",
    "            response_parts = full_response.split(\"<start_of_turn>model\\n\")[1]\n",
    "            if \"<end_of_turn>\" in response_parts:\n",
    "                summary = response_parts.split(\"<end_of_turn>\")[0].strip()\n",
    "            else:\n",
    "                summary = response_parts.strip()\n",
    "        else:\n",
    "            # 프롬프트 제거\n",
    "            summary = full_response.replace(prompt, \"\").strip()\n",
    "            \n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"요약 파싱 오류: {e}\")\n",
    "        # 오류 발생 시 전체 응답에서 프롬프트 부분 제거 시도\n",
    "        return full_response.replace(prompt, \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터셋 가져오기\n",
    "def load_dataset(file_path, max_samples=50):\n",
    "    \"\"\"JSON 파일에서 뉴스 문서와 요약 데이터셋 로드\"\"\"\n",
    "    print(f\"데이터셋 로딩 중: {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # 데이터셋 구조 확인\n",
    "        if \"documents\" in data:\n",
    "            # 문서 데이터 추출\n",
    "            documents = data[\"documents\"]\n",
    "            processed_data = []\n",
    "            \n",
    "            for doc in documents:\n",
    "                # 원문 텍스트 추출 (text는 배열 구조)\n",
    "                original_text = \"\"\n",
    "                if \"text\" in doc:\n",
    "                    # 문장들을 하나의 텍스트로 합치기\n",
    "                    for paragraph in doc[\"text\"]:\n",
    "                        for sent_obj in paragraph:\n",
    "                            if \"sentence\" in sent_obj:\n",
    "                                original_text += sent_obj[\"sentence\"] + \" \"\n",
    "                \n",
    "                # 요약문 추출\n",
    "                summary = \"\"\n",
    "                if \"abstractive\" in doc and doc[\"abstractive\"]:\n",
    "                    summary = doc[\"abstractive\"][0] if isinstance(doc[\"abstractive\"], list) else doc[\"abstractive\"]\n",
    "                \n",
    "                # 필요한 정보만 추출하여 데이터프레임용 딕셔너리 생성\n",
    "                processed_doc = {\n",
    "                    \"id\": doc.get(\"id\", \"\"),\n",
    "                    \"title\": doc.get(\"title\", \"\"),\n",
    "                    \"text\": original_text.strip(),\n",
    "                    \"summary\": summary,\n",
    "                    \"category\": doc.get(\"category\", \"\"),\n",
    "                    \"media_name\": doc.get(\"media_name\", \"\")\n",
    "                }\n",
    "                \n",
    "                processed_data.append(processed_doc)\n",
    "            \n",
    "            # 데이터프레임 생성\n",
    "            df = pd.DataFrame(processed_data)\n",
    "            \n",
    "        else:\n",
    "            # 다른 구조의 JSON 처리\n",
    "            print(\"표준 구조가 아닌 JSON 파일입니다.\")\n",
    "            if isinstance(data, list):\n",
    "                df = pd.DataFrame(data)\n",
    "            else:\n",
    "                df = pd.DataFrame([data])\n",
    "            \n",
    "            # 컬럼 이름 확인 및 변환\n",
    "            if 'article' in df.columns and 'text' not in df.columns:\n",
    "                df['text'] = df['article']\n",
    "            if 'summary' not in df.columns and 'abstractive' in df.columns:\n",
    "                df['summary'] = df['abstractive']\n",
    "        \n",
    "        # 빈 텍스트나 요약이 있는 행 제거\n",
    "        df = df.dropna(subset=['text'])\n",
    "        df = df[df['text'].str.strip() != '']\n",
    "        \n",
    "        # 최대 샘플 수 제한\n",
    "        if len(df) > max_samples:\n",
    "            df = df.sample(max_samples, random_state=42)\n",
    "        \n",
    "        print(f\"데이터셋 로딩 완료: {len(df)} 샘플\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"데이터셋 로딩 실패: {e}\")\n",
    "        # 예시 데이터 생성\n",
    "        print(\"예시 데이터 사용\")\n",
    "        example_data = {\n",
    "            'text': [\n",
    "                \"한국은행이 통화정책 결정 회의에서 기준금리를 동결했다. 한국은행은 지난해 4분기 이후 계속된 경기침체의 영향으로 고용 시장이 위축되고 있으며, 물가상승률은 목표 수준으로 안정되고 있다고 판단했다. 시장 전문가들은 한국 경제의 회복세가 예상보다 더디게 진행되고 있어 금리 인하 가능성도 있다고 전망했다.\",\n",
    "                \"금융위원회는 오늘 가계부채 관리 방안을 발표했다. 주요 내용은 총부채원리금상환비율(DSR) 규제를 40%로 강화하고, 다주택자에 대한 주택담보대출 제한을 확대하는 것이다. 또한 실수요자에 대한 대출 지원은 확대하되, 투기 목적의 대출에는 제재를 강화하는 투트랙 전략을 펼치기로 했다.\"\n",
    "            ],\n",
    "            'summary': [\n",
    "                \"한국은행이 통화정책 결정 회의에서 기준금리 동결, 경기침체로 인한 고용시장 위축과 물가 안정 판단\",\n",
    "                \"금융위, 가계부채 관리방안 발표 - DSR 40% 강화, 다주택자 대출제한 확대, 실수요자 지원 확대\"\n",
    "            ]\n",
    "        }\n",
    "        return pd.DataFrame(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. SHAP용 파이프라인 및 Explainer 구성\n",
    "class SummarizationPipeline:\n",
    "    def __init__(self, model, tokenizer, embedder):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embedder = embedder\n",
    "        self.original_text = None\n",
    "        self.reference_summary = None\n",
    "        self.perturbation_count = 0\n",
    "    \n",
    "    def set_reference(self, text, summary=None):\n",
    "        \"\"\"원본 텍스트와 참조 요약 설정\"\"\"\n",
    "        self.original_text = text\n",
    "        self.perturbation_count = 0\n",
    "        \n",
    "        if summary is None:\n",
    "            # 참조 요약이 없으면 모델로 생성\n",
    "            print(\"참조 요약 생성 중...\")\n",
    "            self.reference_summary = summarize_text(text)\n",
    "            print(f\"생성된 참조 요약: {self.reference_summary}\")\n",
    "        else:\n",
    "            self.reference_summary = summary\n",
    "            print(f\"제공된 참조 요약: {self.reference_summary}\")\n",
    "        \n",
    "        # 참조 요약 임베딩 미리 계산\n",
    "        self.reference_embedding = self.embedder.encode(\n",
    "            self.reference_summary, convert_to_tensor=True\n",
    "        )\n",
    "\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        \"\"\"\n",
    "        SHAP용 호출 함수. Perturbation된 텍스트 목록을 받아 각각의 요약 품질 점수 반환\n",
    "        \"\"\"\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "        \n",
    "        batch_size = min(2, len(texts))  # 배치 크기 줄임(메모리 고려)\n",
    "        all_scores = []\n",
    "        \n",
    "        # 진행 상황 출력\n",
    "        # tqdm 진행 바 설정\n",
    "        total = getattr(self, \"_expected_perturbations\", 100)\n",
    "        pbar = tqdm(total=total, desc=\"🔍 SHAP perturbation 진행\", unit=\"step\", leave=True)\n",
    "        pbar.n = self.perturbation_count  # 이전에 진행된 수 반영\n",
    "        pbar.refresh()\n",
    "         \n",
    "                \n",
    "        # 배치 단위로 처리\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_scores = []\n",
    "            \n",
    "            for text in batch_texts:\n",
    "                # 넘파이 배열이나 텐서 처리\n",
    "                if isinstance(text, (np.ndarray, torch.Tensor)):\n",
    "                    text = text.tolist()\n",
    "\n",
    "                # 리스트 → 첫 원소 꺼냄\n",
    "                if isinstance(text, list) and len(text) > 0:\n",
    "                    text = text[0]\n",
    "\n",
    "                # 문자열인지 최종 확인\n",
    "                if not isinstance(text, str):\n",
    "                    print(f\"[!] 텍스트를 문자열로 변환할 수 없음: {type(text)}\")\n",
    "                    batch_scores.append(0.0)\n",
    "                    continue\n",
    "                \n",
    "                # 빈 텍스트 체크\n",
    "                if not text.strip():\n",
    "                    batch_scores.append(0.0)\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    # 요약 생성\n",
    "                    summary = summarize_text(text)\n",
    "                    \n",
    "                    if not summary.strip():\n",
    "                        print(\"[!] 요약 결과가 공백입니다. 점수 계산 생략\")\n",
    "                        batch_scores.append(0.0)\n",
    "                        continue\n",
    "                    \n",
    "                    # 생성된 요약의 임베딩 계산\n",
    "                    summary_embedding = self.embedder.encode(\n",
    "                        summary, convert_to_tensor=True\n",
    "                    )\n",
    "\n",
    "                    # NaN 체크 및 처리\n",
    "                    if torch.isnan(summary_embedding).any() or torch.isnan(self.reference_embedding).any():\n",
    "                        print(f\"[!] NaN detected in embeddings. 요약 텍스트: {summary}\")\n",
    "                        batch_scores.append(0.0)\n",
    "                        continue\n",
    "                    \n",
    "                    # 참조 요약과의 유사도 계산 (코사인 유사도)\n",
    "                    similarity = util.cos_sim(\n",
    "                        summary_embedding, self.reference_embedding\n",
    "                    ).item()\n",
    "                    \n",
    "                    # 점수 범위 보정\n",
    "                    normalized_score = max(0.0, min(1.0, float(similarity)))\n",
    "                    batch_scores.append(normalized_score)\n",
    "\n",
    "                    self.perturbation_count += 1\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[!] 점수 계산 오류: {str(e)}\")\n",
    "                    batch_scores.append(0.0)  # 오류 시 0점 처리\n",
    "            \n",
    "            all_scores.extend(batch_scores)\n",
    "                    \n",
    "            # 🔍 디버깅 로그 추가\n",
    "            print(f\"[DEBUG] texts 길이: {len(texts)}\")\n",
    "            print(f\"[DEBUG] 현재 batch_texts 길이: {len(batch_texts)}\")\n",
    "            print(f\"[DEBUG] batch_scores 길이: {len(batch_scores)}\")\n",
    "            print(f\"[DEBUG] 누적 all_scores 길이: {len(all_scores)}\")\n",
    "    \n",
    "        # 무조건 입력 개수와 출력 개수 맞춰주기\n",
    "        if len(all_scores) != len(texts):\n",
    "            print(f\"[!] Warning: 입력 수({len(texts)})와 출력 수({len(all_scores)})가 다릅니다. 0.0으로 채움\")\n",
    "            if len(all_scores) > len(texts):\n",
    "                # 너무 많이 만든 경우 자르기\n",
    "                all_scores = all_scores[:len(texts)]\n",
    "            else:\n",
    "                # 부족한 경우 0.0으로 채우기\n",
    "                while len(all_scores) < len(texts):\n",
    "                    all_scores.append(0.0)\n",
    "\n",
    "        if len(texts) == 1:\n",
    "            return [float(all_scores[0])]  # SHAP이 1개만 요청한 경우\n",
    "        else:\n",
    "            return [float(s) for s in all_scores]\n",
    "    \n",
    "    def explain_specific_tokens(self, tokens, top_n=5):\n",
    "        \"\"\"\n",
    "        특정 토큰들의 중요도를 개별적으로 분석\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        original_summary = summarize_text(self.original_text)\n",
    "        \n",
    "        for token in tokens:\n",
    "            # 해당 토큰을 제거한 텍스트 생성\n",
    "            removed_text = self.original_text.replace(token, \"\")\n",
    "            \n",
    "            # 제거 후 요약 생성\n",
    "            removed_summary = summarize_text(removed_text)\n",
    "            \n",
    "            # 원본 요약과 제거 후 요약의 유사도 계산\n",
    "            original_emb = self.embedder.encode(original_summary, convert_to_tensor=True)\n",
    "            removed_emb = self.embedder.encode(removed_summary, convert_to_tensor=True)\n",
    "            \n",
    "            # 유사도 차이가 클수록 해당 토큰이 중요함\n",
    "            similarity = util.cos_sim(original_emb, removed_emb).item()\n",
    "            importance = 1.0 - similarity\n",
    "            \n",
    "            results.append({\n",
    "                \"token\": token,\n",
    "                \"importance\": importance,\n",
    "                \"original_summary\": original_summary,\n",
    "                \"removed_summary\": removed_summary\n",
    "            })\n",
    "            \n",
    "        # 중요도 순으로 정렬\n",
    "        results.sort(key=lambda x: x[\"importance\"], reverse=True)\n",
    "        return results[:top_n]\n",
    "\n",
    "\n",
    "def analyze_with_shap(text, reference_summary=None, num_samples=100, verbose=True):\n",
    "    \"\"\"\n",
    "    단일 텍스트에 대해 SHAP 분석 수행\n",
    "    \n",
    "    Args:\n",
    "        text: 분석할 원문 텍스트\n",
    "        reference_summary: 참조 요약 (없으면 모델로 생성)\n",
    "        num_samples: SHAP 샘플링 수\n",
    "        verbose: 자세한 출력 여부\n",
    "    \n",
    "    Returns:\n",
    "        shap_values: SHAP 값\n",
    "        summary: 생성된 요약\n",
    "        pipeline: 분석에 사용된 파이프라인 객체\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\\n원문 분석 시작\\n{'='*80}\")\n",
    "        print(f\"원문 (일부): {text[:200]}...\")\n",
    "    \n",
    "    # 빈 텍스트 확인\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        raise ValueError(\"분석할 텍스트가 비어 있습니다.\")\n",
    "    \n",
    "    # 파이프라인 초기화 및 참조 설정\n",
    "    pipeline = SummarizationPipeline(model, tokenizer, embedder)\n",
    "    pipeline.set_reference(text, reference_summary)\n",
    "    \n",
    "    # SHAP Explainer 생성\n",
    "    try:\n",
    "        # 단어 단위로 분할\n",
    "        words = text.split()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"SHAP Explainer 초기화 중...\")\n",
    "            print(f\"텍스트 길이: {len(text)}, 단어 수: {len(words)}\")\n",
    "        \n",
    "        mask_token = tokenizer.pad_token or tokenizer.eos_token or \"…\"  # fallback\n",
    "        masker = shap.maskers.Text(tokenizer=tokenizer, mask_token=mask_token)          \n",
    "        \n",
    "        # Partition 마스커 사용 (더 안정적)\n",
    "        explainer = shap.Explainer(pipeline, masker)\n",
    "        \n",
    "        # 샘플 수 자동 조정 (너무 많으면 오래 걸림)\n",
    "        num_features = len(words)\n",
    "        adjusted_samples = min(max(2 * num_features + 1, 50), num_samples)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"SHAP 값 계산 중 (단어 수: {num_features}, 샘플 수: {adjusted_samples})...\")\n",
    "        \n",
    "        # SHAP 값 계산 - 단일 데이터로 명시\n",
    "        shap_values = explainer([text], max_evals=30)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"SHAP 분석 완료\")\n",
    "            print(f\"SHAP 값 형태: {shap_values.values.shape}\")\n",
    "        \n",
    "        return shap_values, pipeline.reference_summary, pipeline\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP 분석 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"더 단순한 설정으로 SHAP 분석 재시도...\")\n",
    "        try:\n",
    "            # 더 단순하고 안정적인 접근방식 사용\n",
    "            # 텍스트 직접 처리\n",
    "            tokenized_text = text.split()\n",
    "            \n",
    "            # 수동으로 SHAP 값 생성\n",
    "            dummy_values = np.zeros((1, len(tokenized_text)))\n",
    "            \n",
    "            # 각 토큰의 중요도를 간단히 계산 (임베딩 유사도 기반)\n",
    "            original_summary = summarize_text(text)\n",
    "            \n",
    "            for i, token in enumerate(tokenized_text):\n",
    "                # 해당 토큰 제거\n",
    "                modified_text = ' '.join([t for j, t in enumerate(tokenized_text) if j != i])\n",
    "                \n",
    "                try:\n",
    "                    # 수정된 텍스트로 요약 생성\n",
    "                    modified_summary = summarize_text(modified_text)\n",
    "                    \n",
    "                    # 두 요약의 임베딩 비교\n",
    "                    orig_emb = pipeline.embedder.encode(original_summary, convert_to_tensor=True)\n",
    "                    mod_emb = pipeline.embedder.encode(modified_summary, convert_to_tensor=True)\n",
    "                    \n",
    "                    # 유사도 계산 (1 - 유사도 = 중요도)\n",
    "                    similarity = util.cos_sim(orig_emb, mod_emb).item()\n",
    "                    importance = 1.0 - similarity\n",
    "                    \n",
    "                    # 중요도 저장\n",
    "                    dummy_values[0, i] = importance\n",
    "                except Exception as e2:\n",
    "                    print(f\"토큰 '{token}' 처리 중 오류: {e2}\")\n",
    "                    dummy_values[0, i] = 0.0\n",
    "            \n",
    "            # SHAP 결과와 유사한 객체 생성\n",
    "            class CustomShapValues:\n",
    "                def __init__(self, values, data, feature_names):\n",
    "                    self.values = values\n",
    "                    self.data = data\n",
    "                    self.feature_names = feature_names\n",
    "                    self.output_names = [\"importance\"]\n",
    "                    self.base_values = np.zeros(1)\n",
    "            \n",
    "            # 결과 반환\n",
    "            shap_obj = CustomShapValues(\n",
    "                values=dummy_values,\n",
    "                data=np.array([text]),\n",
    "                feature_names=tokenized_text\n",
    "            )\n",
    "            \n",
    "            print(\"대체 SHAP 분석 완료\")\n",
    "            return shap_obj, original_summary, pipeline\n",
    "            \n",
    "        except Exception as retry_error:\n",
    "            print(f\"대체 SHAP 분석도 실패: {retry_error}\")\n",
    "            traceback.print_exc()\n",
    "            raise ValueError(\"모든 SHAP 분석 방법이 실패했습니다.\")\n",
    "\n",
    "def print_important_features(shap_values, summary, top_n=10):\n",
    "    \"\"\"\n",
    "    SHAP 값을 기반으로 중요 feature를 출력\n",
    "    \"\"\"\n",
    "    # SHAP 값의 절대값을 기준으로 정렬\n",
    "    token_importances = []\n",
    "    \n",
    "    try:\n",
    "        # 데이터 형식에 따라 다르게 처리\n",
    "        if hasattr(shap_values, 'data') and isinstance(shap_values.data, np.ndarray):\n",
    "            text_data = shap_values.data[0]\n",
    "            if isinstance(text_data, np.ndarray) and text_data.size == 1:\n",
    "                text_data = text_data.item()\n",
    "        else:\n",
    "            # 대체 방식\n",
    "            text_data = shap_values.data[0] if hasattr(shap_values, 'data') else \"텍스트 데이터 없음\"\n",
    "        \n",
    "        # 토큰 분할\n",
    "        tokens = text_data.split() if isinstance(text_data, str) else []\n",
    "        \n",
    "        # 토큰과 SHAP 값 매핑\n",
    "        for i, token in enumerate(tokens):\n",
    "            if i < shap_values.values.shape[1]:  # 인덱스 범위 확인\n",
    "                importance = abs(shap_values.values[0][i])\n",
    "                raw_value = shap_values.values[0][i]\n",
    "                token_importances.append((token, importance, raw_value))\n",
    "        \n",
    "        # 중요도 기준 정렬\n",
    "        sorted_importances = sorted(token_importances, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"생성된 요약: {summary}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"상위 {top_n}개 중요 단어 (SHAP 기준):\")\n",
    "        print(f\"{'단어':<15} | {'중요도':>10} | {'영향':>10} | {'해석'}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "        \n",
    "        for token, importance, raw_value in sorted_importances[:top_n]:\n",
    "            effect = \"긍정적 영향\" if raw_value > 0 else \"부정적 영향\"\n",
    "            print(f\"{token:<15} | {importance:>10.4f} | {raw_value:>10.4f} | {effect}\")\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"중요 특성 출력 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"간소화된 분석 결과 출력:\")\n",
    "        print(f\"요약: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 로딩 중: ./data/train_original.json\n",
      "데이터셋 로딩 완료: 10 샘플\n",
      "\n",
      "총 10개 샘플 분석 시작\n",
      "\n",
      "샘플 1/10 분석:\n",
      "\n",
      "================================================================================\n",
      "원문 분석 시작\n",
      "================================================================================\n",
      "원문 (일부): 최명국 송하진 지사, 방중 주요 성과로 '군산~연운항' 항로 개설 협의 꼽아 장쑤성 당서기 \"바닷길 통한 협력, 적극 검토\" 두 지역 인적 교류 활발, 지난해 석도 항로 증편 송하진 전북도지사가 중국 장쑤성(강소성) 방문의 주요 성과로 중국 측과의 '군산~장쑤성 연운항' 항로 개설 협의를 꼽았다. 송하진 도지사는 1일 출입기자들과 만나 \"군산과 장쑤성 연운...\n",
      "제공된 참조 요약: 송하진 전북도지사가 중국 장쑤성을 방문해 러우 친지앤 당서기와 새만금 산단 5공구 공동투자 활용안에 대해 협의하고 군산과 장쑤성 연운항 간 신규 여객 항로 개설을 통한 협력방안을 논의했다.\n",
      "SHAP Explainer 초기화 중...\n",
      "텍스트 길이: 892, 단어 수: 219\n",
      "SHAP 값 계산 중 (단어 수: 219, 샘플 수: 5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] input_ids shape: torch.Size([1, 38])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 SHAP perturbation 진행:   1%|          | 1/100 [11:13<18:31:52, 673.86s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] texts 길이: 1\n",
      "[DEBUG] 현재 batch_texts 길이: 1\n",
      "[DEBUG] batch_scores 길이: 1\n",
      "[DEBUG] 누적 all_scores 길이: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] input_ids shape: torch.Size([1, 595])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 595])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 SHAP perturbation 진행:   2%|▏         | 2/100 [11:14<9:10:34, 337.09s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] texts 길이: 1\n",
      "[DEBUG] 현재 batch_texts 길이: 1\n",
      "[DEBUG] batch_scores 길이: 1\n",
      "[DEBUG] 누적 all_scores 길이: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] input_ids shape: torch.Size([1, 306])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 306])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 SHAP perturbation 진행:   3%|▎         | 3/100 [11:11<6:01:44, 223.76s/step]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6468/2163360236.py\", line 218, in analyze_with_shap\n",
      "    shap_values = explainer([text], max_evals=30)\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/explainers/_partition.py\", line 173, in __call__\n",
      "    return super().__call__(\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/explainers/_explainer.py\", line 366, in __call__\n",
      "    row_result = self.explain_row(\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/explainers/_partition.py\", line 229, in explain_row\n",
      "    self.owen(fm, self._curr_base_value, f11, max_evals - 2, outputs, fixed_context, batch_size, silent)\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/explainers/_partition.py\", line 339, in owen\n",
      "    fout = fm(batch_masks)\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py\", line 67, in __call__\n",
      "    return self._full_masking_call(masks, batch_size=batch_size)\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py\", line 143, in _full_masking_call\n",
      "    _assert_output_input_match(joined_masked_inputs, outputs)\n",
      "  File \"/home/elicer/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py\", line 282, in _assert_output_input_match\n",
      "    assert len(outputs) == len(inputs[0]), (\n",
      "AssertionError: The model produced 1 output rows when given 2 input rows! Check the implementation of the model you provided for errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] texts 길이: 1\n",
      "[DEBUG] 현재 batch_texts 길이: 1\n",
      "[DEBUG] batch_scores 길이: 1\n",
      "[DEBUG] 누적 all_scores 길이: 1\n",
      "SHAP 분석 중 오류 발생: The model produced 1 output rows when given 2 input rows! Check the implementation of the model you provided for errors.\n",
      "더 단순한 설정으로 SHAP 분석 재시도...\n",
      "[DEBUG] input_ids shape: torch.Size([1, 595])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 595])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 587])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 587])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 591])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 591])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 591])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 591])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 587])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 587])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 594])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 588])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 588])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 591])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 591])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 593])\n",
      "[DEBUG] input_ids shape: torch.Size([1, 592])\n",
      "[DEBUG] input_ids (앞 30개): tensor([     2,    105,   2364,    107, 179886, 200086, 234416,   9554,  68564,\n",
      "         23591, 239114, 219770, 236761,  86394,  29950, 237430,  24566,  54422,\n",
      "        237558,  94485,  93860, 143495,  22063,  23591, 239114, 219770, 236761,\n",
      "           108, 237351, 237470], device='cuda:0')\n",
      ">>> input shape: torch.Size([1, 592])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 218\u001b[0m, in \u001b[0;36manalyze_with_shap\u001b[0;34m(text, reference_summary, num_samples, verbose)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# SHAP 값 계산 - 단일 데이터로 명시\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/explainers/_partition.py:173\u001b[0m, in \u001b[0;36mPartitionExplainer.__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/explainers/_explainer.py:366\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[0;32m--> 366\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/explainers/_partition.py:229\u001b[0m, in \u001b[0;36mPartitionExplainer.explain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(out_shape)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mowen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curr_base_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# if False:\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m#     if self.multi_output:\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m#         return [self.dvalues[:,i] for i in range(self.dvalues.shape[1])], oinds\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# drop the interaction terms down onto self.values\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/explainers/_partition.py:339\u001b[0m, in \u001b[0;36mPartitionExplainer.owen\u001b[0;34m(self, fm, f00, f11, max_evals, output_indexes, fixed_context, batch_size, silent)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch_args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 339\u001b[0m     fout \u001b[38;5;241m=\u001b[39m \u001b[43mfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_indexes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py:67\u001b[0m, in \u001b[0;36mMaskedModel.__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_full_masking_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py:143\u001b[0m, in \u001b[0;36mMaskedModel._full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mjoined_masked_inputs)\n\u001b[0;32m--> 143\u001b[0m \u001b[43m_assert_output_input_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoined_masked_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m all_outputs\u001b[38;5;241m.\u001b[39mappend(outputs)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py:282\u001b[0m, in \u001b[0;36m_assert_output_input_match\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_assert_output_input_match\u001b[39m(inputs, outputs):\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs[\u001b[38;5;241m0\u001b[39m]), (\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model produced \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(outputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m output rows when given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input rows! Check the implementation of the model you provided for errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: The model produced 1 output rows when given 2 input rows! Check the implementation of the model you provided for errors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m샘플 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 분석:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     shap_values, summary, _ \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_with_shap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 샘플링 수 조정 (높을수록 정확하지만 느림)\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# 중요 feature 출력\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     print_important_features(shap_values, summary, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 249\u001b[0m, in \u001b[0;36manalyze_with_shap\u001b[0;34m(text, reference_summary, num_samples, verbose)\u001b[0m\n\u001b[1;32m    245\u001b[0m modified_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([t \u001b[38;5;28;01mfor\u001b[39;00m j, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tokenized_text) \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m i])\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# 수정된 텍스트로 요약 생성\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     modified_summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# 두 요약의 임베딩 비교\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     orig_emb \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39membedder\u001b[38;5;241m.\u001b[39mencode(original_summary, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36msummarize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> input shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 35\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_config\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# GPU에서 생성\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     37\u001b[0m         output \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 첫 번째 결과만 사용 (batch_size=1)\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2326\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2319\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2320\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2321\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2322\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2323\u001b[0m     )\n\u001b[1;32m   2325\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2326\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2337\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2339\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2340\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2341\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2342\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2343\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3289\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3287\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3289\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3292\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3293\u001b[0m     outputs,\n\u001b[1;32m   3294\u001b[0m     model_kwargs,\n\u001b[1;32m   3295\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3296\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:1351\u001b[0m, in \u001b[0;36mGemma3ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **lm_kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(input_ids \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mignore_index, labels)\n\u001b[1;32m   1348\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_causal_mask(\n\u001b[1;32m   1349\u001b[0m     attention_mask, token_type_ids, past_key_values, cache_position, inputs_embeds, is_training\n\u001b[1;32m   1350\u001b[0m )\n\u001b[0;32m-> 1351\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1366\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:978\u001b[0m, in \u001b[0;36mGemma3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:756\u001b[0m, in \u001b[0;36mGemma3TextModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, last_cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    743\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    744\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    753\u001b[0m         last_cache_position,\n\u001b[1;32m    754\u001b[0m     )\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 756\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_cache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_cache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:461\u001b[0m, in \u001b[0;36mGemma3DecoderLayer.forward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, last_cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    460\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_feedforward_layernorm(hidden_states)\n\u001b[0;32m--> 461\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_feedforward_layernorm(hidden_states)\n\u001b[1;32m    463\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:119\u001b[0m, in \u001b[0;36mGemma3MLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 119\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5. 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"./data/train_original.json\" # 실제 파일 경로로 변경\n",
    "    df = load_dataset(dataset_path, max_samples=10)  # 테스트용 10개만\n",
    "    \n",
    "    # 텍스트와 참조 요약 추출\n",
    "    texts = df[\"text\"].tolist()\n",
    "    references = df[\"summary\"].tolist() if \"summary\" in df.columns else [None] * len(texts)\n",
    "    \n",
    "    print(f\"\\n총 {len(texts)}개 샘플 분석 시작\")\n",
    "    \n",
    "    # 각 샘플에 대해 SHAP 분석 수행\n",
    "    for i, (text, reference) in enumerate(zip(texts, references)):\n",
    "        print(f\"\\n샘플 {i+1}/{len(texts)} 분석:\")\n",
    "        \n",
    "        try:\n",
    "            shap_values, summary, _ = analyze_with_shap(\n",
    "                text, \n",
    "                reference_summary=reference,\n",
    "                num_samples=5,  # 샘플링 수 조정 (높을수록 정확하지만 느림)\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            # 중요 feature 출력\n",
    "            print_important_features(shap_values, summary, top_n=15)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"샘플 {i+1} 분석 중 오류 발생: {e}\")\n",
    "            print(\"이 샘플은 건너뜁니다.\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n모든 분석 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
